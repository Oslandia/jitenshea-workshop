{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze data with machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although a lot of interesting question could be addressed with this dataset, we will focus on one single use case, summarized by the following question: **Can we group the shared-bike station regarding their occupation chronicle?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "import os\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOST = \"localhost\"\n",
    "PORT = 5432\n",
    "USER = \"rde\"\n",
    "DBNAME = \"jitenshea\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_engine():\n",
    "    url = \"postgresql://{user}@{host}:{port}/{dbname}\".format(user=USER, host=HOST, port=PORT, dbname=DBNAME)\n",
    "    return create_engine(url)\n",
    "engine = get_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute stations clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the previously stored timeseries data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = date.today()\n",
    "start = stop - timedelta(7)\n",
    "start, stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "availability_input_file = \"{begin}-{end}.csv\".format(begin=start.strftime(\"%Y%m%d\"), end=stop.strftime(\"%Y%m%d\"))\n",
    "availability_input_path = os.path.join(DATADIR, \"lyon\", \"history\", availability_input_file)\n",
    "availability_input_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(availability_input_path, parse_dates=[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.timestamp.min(), df.timestamp.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to control the clustering process in a wider way, we may consider the time period as a input parameter, hence select the data accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can note that timestamped data are stored with a timezone info, hence we must declare timezone-aware datetimes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today()\n",
    "stop = datetime(today.year, today.month, today.day, 0, 0, tzinfo=pytz.utc)\n",
    "start = stop - timedelta(7)\n",
    "start, stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"timestamp\"] >= start) & (df[\"timestamp\"] <= stop)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we remove from the analysis shared-bike stations that looks unused during the period (the station remained empty)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"ts\", \"nb_bikes\", \"station_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bikes = df.groupby(\"station_id\")[\"nb_bikes\"].max()\n",
    "unactive_stations = max_bikes[max_bikes==0].index.tolist()\n",
    "df = df[~ df[\"station_id\"].isin(unactive_stations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unactive_stations, df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we resample the data each 5 minutes and group it with respect to station IDs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = (df.set_index(\"ts\")\n",
    "       .groupby(\"station_id\")[\"nb_bikes\"]\n",
    "       .resample(\"5T\")\n",
    "       .mean()\n",
    "       .bfill()\n",
    "       .unstack(0))\n",
    "rdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Spoiler:* this data is already sampled into 5-minute periods, however we keep the code as is for data consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can remove the week-end days from analysis, by anticipating that they may \"pollute\" the cluster formation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = rdf[rdf.index.weekday < 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we apply a naive normalization scheme to consider station filling rates instead of bike quantities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = rdf / rdf.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data is normalized, we can aggregate availability at hour level for clustering step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf[\"hour\"] = rdf.index.hour\n",
    "rdf = rdf.groupby(\"hour\").mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last operation provides the typical week day profile of each station, at each hour of the day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf.iloc[:,:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the k-mean algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a clusterable dataset! Let apply the easiest step..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are, `scikit-learn` makes it as easy as two lines of Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=N_CLUSTERS, random_state=0)\n",
    "model.fit(rdf.T)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.DataFrame({\"station_id\": rdf.columns, \"cluster_id\": model.labels_})\n",
    "df_centroids = pd.DataFrame(model.cluster_centers_, columns=[\"h{:02d}\".format(i) for i in range(24)]).reset_index()\n",
    "df_centroids.columns.values[0] = \"cluster_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each station, we have a cluster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette(n_colors=N_CLUSTERS)\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_labels = [\": \".join([str(u), str(c)]) + \" stations\" for u, c in zip(df_labels.cluster_id.unique(), df_labels.cluster_id.value_counts())]\n",
    "cluster_pie = plt.pie(labels=pie_labels, x=df_labels.cluster_id.value_counts(), colors=palette)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and for each cluster, we have the centroid expressed as a typical week day profile!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_centroids.iloc[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "ax.set_ylim((0, 1))\n",
    "centroid_plot = sns.lineplot(data=df_centroids.drop(columns=[\"cluster_id\"]).T, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the clustering outputs to the application database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We previously clustered the shared-bike stations and deduced typical week day profiles, the job is almost done for ending the loop: we still have to store this new produced data to the database.\n",
    "\n",
    "As the produced outputs highly depends on the chosen time period, it is recommended to store the start and stop datetimes as well: this modelization choice will allow us to store multiple clustering outputs into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels.loc[:, \"start\"] = start\n",
    "df_labels.loc[:, \"stop\"] = stop\n",
    "df_centroids.loc[:, \"start\"] = start\n",
    "df_centroids.loc[:, \"stop\"] = stop\n",
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final transformation, we consider string-formatted station IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels.loc[:, \"station_id\"] = df_labels[\"station_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(\"DROP TABLE IF EXISTS lyon.cluster;\")\n",
    "df_labels.to_sql(\"cluster\", schema=\"lyon\", con=engine, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(\"DROP TABLE IF EXISTS lyon.centroid;\")\n",
    "df_centroids.to_sql(\"centroid\", schema=\"lyon\", con=engine, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all folks, for populating the database!\n",
    "\n",
    "Now the database contains:\n",
    "- the shared-bike station description;\n",
    "- one week of bike availability timeseries;\n",
    "- the clustering outputs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
